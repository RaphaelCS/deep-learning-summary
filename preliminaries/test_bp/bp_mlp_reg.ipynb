{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python_defaultSpec_1596377880216",
   "display_name": "Python 3.8.3 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test my backpropagation calculus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "IN_SIZE, OUT_SIZE = 784, 100\n",
    "HIDDEN_SIZE = [512, 1024, 1024]\n",
    "\n",
    "IN_SIZE, OUT_SIZE = 300, 200\n",
    "HIDDEN_SIZE = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "x = torch.empty((1, IN_SIZE)).uniform_(-10, 10)\n",
    "y = torch.empty((1, OUT_SIZE)).uniform_(-10, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestNet(nn.Module):\n",
    "    def __init__(self, n_input, n_hiddens, n_output):\n",
    "        super(TestNet, self).__init__()\n",
    "\n",
    "        n_layers = [n_input] + n_hiddens + [n_output]\n",
    "        self.layers = nn.ModuleList()\n",
    "        for i in range(len(n_layers) - 1):\n",
    "            self.layers.append(nn.Linear(n_layers[i], n_layers[i+1]))\n",
    "    \n",
    "    def forward(self, X):\n",
    "        self.z, self.a = [], [X]\n",
    "        for layer in self.layers:\n",
    "            X = layer(X)\n",
    "            self.z.append(X)\n",
    "            X = torch.sigmoid(X)\n",
    "            self.a.append(X)\n",
    "        return X\n",
    "\n",
    "def init_weights(m):\n",
    "    if type(m) == nn.Linear:\n",
    "        nn.init.uniform_(m.weight, -10, 10)\n",
    "        nn.init.uniform_(m.bias, -10, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "TestNet(\n  (layers): ModuleList(\n    (0): Linear(in_features=300, out_features=200, bias=True)\n  )\n)"
     },
     "metadata": {},
     "execution_count": 22
    }
   ],
   "source": [
    "net = TestNet(IN_SIZE, HIDDEN_SIZE, OUT_SIZE)\n",
    "net.apply(init_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.SGD(net.parameters(), lr=0.03)\n",
    "optimizer.zero_grad()\n",
    "\n",
    "loss = nn.MSELoss()\n",
    "loss(net(x), y).backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "torch.Size([200, 300])\ntorch.Size([200])\n"
    }
   ],
   "source": [
    "params = [param for param in net.parameters()]\n",
    "for param in params:\n",
    "    print(param.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def D_sigmoid(x):\n",
    "    return torch.sigmoid(x) * (1 - torch.sigmoid(x))\n",
    "\n",
    "def calculate_gradients(num_layers=4):\n",
    "    delta = [torch.empty(net.z[i].shape[1]) for i in range(num_layers - 1)]\n",
    "    delta.append((net.a[-1] - y) * D_sigmoid(net.z[-1]))\n",
    "    delta[-1] = delta[-1].reshape((-1, 1))\n",
    "\n",
    "    for i in range(num_layers - 1, 0, -1):\n",
    "        delta[i - 1] = (params[i * 2].T @ delta[i]) * D_sigmoid(net.z[i - 1]).T\n",
    "    \n",
    "    gradients = []\n",
    "    for i in range(len(delta)):\n",
    "        gradients.append(delta[i] @ net.a[i])\n",
    "        gradients.append(delta[i])\n",
    "    \n",
    "    return gradients\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "gradients = calculate_gradients(len(HIDDEN_SIZE) + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "tensor([-0.1097, -0.0750,  0.0826, -0.0793, -0.0955,  0.0605, -0.1035,  0.0793,\n        -0.1035, -0.0609, -0.0722, -0.1192,  0.0924,  0.0719,  0.0657,  0.1178,\n         0.0769, -0.1124, -0.1201, -0.0601,  0.0521,  0.0636, -0.0570,  0.0899,\n        -0.0570,  0.1144, -0.1021, -0.0752, -0.1197,  0.0942, -0.0834, -0.1220,\n        -0.1042,  0.1179,  0.0602,  0.1148, -0.0976, -0.0770, -0.1066,  0.0783,\n         0.0634, -0.0617, -0.0629, -0.1227, -0.1116, -0.0792,  0.0581,  0.0743,\n        -0.1145,  0.0805, -0.0565, -0.0692,  0.1226,  0.0566,  0.1116, -0.0858,\n        -0.0880, -0.1226,  0.0732,  0.0542,  0.0718,  0.1043,  0.0726,  0.0917,\n         0.0560, -0.0909,  0.1184,  0.1093,  0.0787,  0.0739, -0.1194,  0.1043,\n        -0.1186,  0.0528, -0.0605,  0.0812,  0.1115, -0.0915, -0.1183,  0.0903,\n        -0.0793, -0.1109,  0.0959,  0.1005, -0.1215, -0.0757, -0.0656,  0.0860,\n         0.1014,  0.0828, -0.0837,  0.0588, -0.1124, -0.1042, -0.0788, -0.0936,\n        -0.1230, -0.1202, -0.0992,  0.0608,  0.0529, -0.0512, -0.0580,  0.0969,\n         0.1224, -0.0647,  0.1128, -0.0690, -0.0842, -0.1138,  0.0637,  0.0571,\n        -0.0785, -0.0874, -0.1079,  0.0815,  0.1107, -0.0803,  0.1038, -0.0722,\n         0.1204,  0.1090,  0.0956,  0.0598, -0.1221, -0.0932,  0.0510, -0.1125,\n         0.0906, -0.0928, -0.0847, -0.0845,  0.0983,  0.0873,  0.1007,  0.1218,\n        -0.0887, -0.0523,  0.0754,  0.0707,  0.0961, -0.0599, -0.0561,  0.1106,\n         0.0588,  0.0907,  0.0587,  0.1218,  0.0556, -0.0821, -0.0920, -0.1194,\n        -0.0960,  0.0986,  0.0632,  0.0815, -0.0582,  0.1001,  0.1138,  0.0796,\n        -0.0804, -0.0897,  0.1205,  0.1070,  0.0574,  0.0667,  0.0626, -0.0917,\n         0.0969, -0.0887, -0.1033, -0.0707,  0.0777, -0.0747, -0.0899,  0.0569,\n        -0.0974,  0.0746, -0.0975, -0.0573, -0.0679, -0.1122,  0.0870,  0.0677,\n         0.0619,  0.1109,  0.0724, -0.1059, -0.1130, -0.0566,  0.0598, -0.0536,\n         0.0847, -0.0537,  0.1077, -0.0961, -0.0708, -0.1127,  0.0887, -0.0786,\n        -0.1149, -0.0981,  0.1110,  0.0566,  0.1081, -0.0919, -0.0725, -0.1004,\n         0.0737,  0.0597, -0.0580, -0.0592, -0.1156, -0.1051, -0.0746,  0.0547,\n         0.0700, -0.1078,  0.0758, -0.0532, -0.0651,  0.1154,  0.0533,  0.1050,\n        -0.0808, -0.0828, -0.1154,  0.0689,  0.0511,  0.0676,  0.0982,  0.0684,\n         0.0863,  0.0527, -0.0856,  0.1114,  0.1029,  0.0741,  0.0696, -0.1124,\n         0.0982, -0.1116, -0.0570,  0.0764,  0.1050, -0.0861, -0.1114,  0.0850,\n        -0.0746, -0.1044,  0.0903,  0.0946, -0.1144, -0.0713, -0.0618,  0.0810,\n         0.0955,  0.0779, -0.0788,  0.0554, -0.1058, -0.0981, -0.0742, -0.0881,\n        -0.1159, -0.1132, -0.0934,  0.0573, -0.0546,  0.0912,  0.1153, -0.0609,\n         0.1062, -0.0650, -0.0793, -0.1072,  0.0600,  0.0538, -0.0739, -0.0823,\n        -0.1016,  0.0767,  0.1042, -0.0756,  0.0977, -0.0680,  0.1134,  0.1027,\n         0.0900,  0.0563, -0.1150, -0.0878, -0.1059,  0.0853, -0.0874, -0.0797,\n        -0.0796,  0.0925,  0.0822,  0.0948,  0.1147, -0.0835,  0.0710,  0.0665,\n         0.0904, -0.0564, -0.0528,  0.1042,  0.0554,  0.0854,  0.0552,  0.1147,\n         0.0523, -0.0773, -0.0866, -0.1125, -0.0904,  0.0929,  0.0595,  0.0767,\n        -0.0548,  0.0942,  0.1072,  0.0749, -0.0757, -0.0844,  0.1135,  0.1007,\n         0.0541,  0.0628,  0.0589, -0.0863,  0.0912, -0.0835]) tensor([-10.9668,  -7.5039,   8.2553,  -7.9325,  -9.5493,   6.0483, -10.3471,\n          7.9272, -10.3538,  -6.0865,  -7.2164, -11.9156,   9.2385,   7.1861,\n          6.5716,  11.7803,   7.6875, -11.2435, -12.0064,  -6.0135,   5.2064,\n          6.3551,  -5.6974,   8.9937,  -5.7027,  11.4433, -10.2116,  -7.5172,\n        -11.9690,   9.4240,  -8.3443, -12.2040, -10.4202,  11.7915,   6.0151,\n         11.4803,  -9.7570,  -7.6955, -10.6596,   7.8320,   6.3401,  -6.1650,\n         -6.2860, -12.2748, -11.1633,  -7.9232,   5.8076,   7.4295, -11.4536,\n          8.0511,  -5.6537,  -6.9152,  12.2608,   5.6639,  11.1552,  -8.5815,\n         -8.7977, -12.2554,   7.3176,   5.4248,   7.1787,  10.4262,   7.2630,\n          9.1674,   5.5976,  -9.0937,  11.8368,  10.9308,   7.8707,   7.3902,\n        -11.9420,  10.4303, -11.8556,   5.2839,  -6.0497,   8.1153,  11.1496,\n         -9.1467, -11.8340,   9.0305,  -7.9280, -11.0917,   9.5866,  10.0524,\n        -12.1455,  -7.5737,  -6.5633,   8.6035,  10.1432,   8.2752,  -8.3654,\n          5.8816, -11.2380, -10.4155,  -7.8795,  -9.3615, -12.3046, -12.0226,\n         -9.9197,   6.0824,   5.2920,  -5.1212,  -5.8013,   9.6888,  12.2428,\n         -6.4694,  11.2781,  -6.9033,  -8.4170, -11.3812,   6.3736,   5.7101,\n         -7.8504,  -8.7439, -10.7903,   8.1492,  11.0684,  -8.0346,  10.3756,\n         -7.2241,  12.0400,  10.9038,   9.5586,   5.9828, -12.2138,  -9.3243,\n          5.1035, -11.2465,   9.0641,  -9.2815,  -8.4681,  -8.4511,   9.8255,\n          8.7324,  10.0656,  12.1828,  -8.8690,  -5.2317,   7.5409,   7.0679,\n          9.6055,  -5.9854,  -5.6097,  11.0631,   5.8840,   9.0703,   5.8659,\n         12.1777,   5.5563,  -8.2125,  -9.2013, -11.9444,  -9.6026,   9.8645,\n          6.3220,   8.1499,  -5.8222,  10.0062,  11.3846,   7.9552,  -8.0413,\n         -8.9681,  12.0508,  10.6957,   5.7437,   6.6663,   6.2604,  -9.1709,\n          9.6909,  -8.8680, -10.3258,  -7.0653,   7.7728,  -7.4689,  -8.9912,\n          5.6948,  -9.7423,   7.4639,  -9.7486,  -5.7307,  -6.7945, -11.2191,\n          8.6985,   6.7660,   6.1875,  11.0917,   7.2381, -10.5863, -11.3046,\n         -5.6620,   5.9837,  -5.3643,   8.4680,  -5.3694,  10.7744,  -9.6147,\n         -7.0778, -11.2694,   8.8731,  -7.8566, -11.4907,  -9.8111,  11.1023,\n          5.6635,  10.8092,  -9.1867,  -7.2457, -10.0366,   7.3743,   5.9695,\n         -5.8047,  -5.9186, -11.5573, -10.5108,  -7.4601,   5.4682,   6.9952,\n        -10.7841,   7.5805,  -5.3233,  -6.5110,  11.5441,   5.3329,  10.5031,\n         -8.0799,  -8.2834, -11.5390,   6.8899,   5.1077,   6.7591,   9.8168,\n          6.8385,   8.6316,   5.2704,  -8.5622,  11.1450,  10.2919,   7.4107,\n          6.9582, -11.2440,   9.8206, -11.1626,  -5.6961,   7.6409,  10.4979,\n         -8.6121, -11.1423,   8.5026,  -7.4646, -10.4434,   9.0262,   9.4648,\n        -11.4356,  -7.1310,  -6.1797,   8.1006,   9.5503,   7.7915,  -7.8764,\n          5.5378, -10.5812,  -9.8067,  -7.4189,  -8.8143, -11.5854, -11.3199,\n         -9.3399,   5.7269,  -5.4622,   9.1225,  11.5272,  -6.0912,  10.6189,\n         -6.4998,  -7.9250, -10.7159,   6.0010,   5.3763,  -7.3915,  -8.2328,\n        -10.1596,   7.6729,  10.4215,  -7.5649,   9.7691,  -6.8018,  11.3362,\n         10.2665,   8.9999,   5.6331, -11.4998,  -8.7793, -10.5891,   8.5343,\n         -8.7390,  -7.9731,  -7.9571,   9.2512,   8.2219,   9.4773,  11.4707,\n         -8.3506,   7.1001,   6.6548,   9.0440,  -5.6356,  -5.2818,  10.4164,\n          5.5400,   8.5401,   5.5230,  11.4659,   5.2316,  -7.7325,  -8.6634,\n        -11.2462,  -9.0414,   9.2880,   5.9524,   7.6735,  -5.4819,   9.4213,\n         10.7191,   7.4902,  -7.5713,  -8.4439,  11.3464,  10.0705,   5.4079,\n          6.2767,   5.8944,  -8.6349,   9.1245,  -8.3496],\n       grad_fn=<IndexBackward>)\ntorch.Size([200, 300]) tensor(12.1816, grad_fn=<MaxBackward1>)\ntensor([]) tensor([], grad_fn=<IndexBackward>)\ntorch.Size([200, 1]) tensor(1.2191, grad_fn=<MaxBackward1>)\n"
    }
   ],
   "source": [
    "for i, param in enumerate(params):\n",
    "    torch_grad = param.grad if len(param.shape) > 1 else param.grad.view(-1, 1)\n",
    "    my_grad = gradients[i]\n",
    "    diff = abs(torch_grad - my_grad)\n",
    "    # print(torch_grad, my_grad)\n",
    "    print(torch_grad[diff > 5], my_grad[diff > 5])\n",
    "    print(diff.shape, torch.max(diff))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}